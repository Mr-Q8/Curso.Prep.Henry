{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mr-Q8/Curso.Prep.Henry/blob/master/_https_www_youtube_com_ElArchivoProhibido_y4o.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LTX-VIDEO Text to Video**"
      ],
      "metadata": {
        "id": "f4p1ysFKMbs_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- You can use the free T4 GPU to run this depending on the output video resolution and number of frames. The default setting runs without issues, but at 768 by 512 output resolution with 121 frames, the decoding process crashes the 12.7GB RAM.  For faster video generation with higher resolutions and frames, use higher GPUs.\n",
        "- If you want to generate a video with n frames, then set frames to n+1. e.g. To generate a video with 72 frames, set frames to 73.\n",
        "- You need to use detailed prompts to get decent results.\n",
        "- Videos are generated at 24fps."
      ],
      "metadata": {
        "id": "EBB00lC6q-DA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Prepare Environment\n",
        "!pip install torch==2.6.0 torchvision==0.21.0\n",
        "%cd /content\n",
        "Always_Load_Models_for_Inference = False\n",
        "Use_t5xxl_fp16 = False\n",
        "# Install dependencies\n",
        "!pip install -q torchsde einops diffusers accelerate xformers==0.0.29.post2\n",
        "!pip install av\n",
        "!git clone https://github.com/Isi-dev/ComfyUI\n",
        "%cd /content/ComfyUI\n",
        "!apt -y install -qq aria2 ffmpeg\n",
        "\n",
        "# Download required models\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Isi99999/LTX-Video/resolve/main/ltx-video-2b-v0.9.5.safetensors -d /content/ComfyUI/models/checkpoints -o ltx-video-2b-v0.9.5.safetensors\n",
        "if Use_t5xxl_fp16:\n",
        "    !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Isi99999/LTX-Video/resolve/main/t5xxl_fp16.safetensors -d /content/ComfyUI/models/text_encoders -o t5xxl_fp16.safetensors\n",
        "else:\n",
        "    !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Isi99999/LTX-Video/resolve/main/t5xxl_fp8_e4m3fn_scaled.safetensors -d /content/ComfyUI/models/text_encoders -o t5xxl_fp8_e4m3fn_scaled.safetensors\n",
        "\n",
        "# Initial setup\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import gc\n",
        "import sys\n",
        "import random\n",
        "import os\n",
        "import imageio\n",
        "from google.colab import files\n",
        "from IPython.display import display, HTML\n",
        "sys.path.insert(0, '/content/ComfyUI')\n",
        "\n",
        "from comfy import model_management\n",
        "\n",
        "from nodes import (\n",
        "    CheckpointLoaderSimple,\n",
        "    CLIPLoader,\n",
        "    CLIPTextEncode,\n",
        "    VAEDecode\n",
        ")\n",
        "\n",
        "from comfy_extras.nodes_custom_sampler import (\n",
        "    KSamplerSelect,\n",
        "    SamplerCustom\n",
        ")\n",
        "\n",
        "from comfy_extras.nodes_lt import (\n",
        "    LTXVConditioning,\n",
        "    LTXVScheduler,\n",
        "    EmptyLTXVLatentVideo\n",
        ")\n",
        "\n",
        "checkpoint_loader = CheckpointLoaderSimple()\n",
        "clip_loader = CLIPLoader()\n",
        "clip_encode_positive = CLIPTextEncode()\n",
        "clip_encode_negative = CLIPTextEncode()\n",
        "scheduler = LTXVScheduler()\n",
        "sampler_select = KSamplerSelect()\n",
        "conditioning = LTXVConditioning()\n",
        "empty_latent_video = EmptyLTXVLatentVideo()\n",
        "sampler = SamplerCustom()\n",
        "vae_decode = VAEDecode()\n",
        "\n",
        "# if not Always_Load_Models_for_Inference:\n",
        "# with torch.inference_mode():\n",
        "#     # Load models\n",
        "#     print(\"Loading Model...\")\n",
        "#     model, _, vae = checkpoint_loader.load_checkpoint(\"ltx-video-2b-v0.9.5.safetensors\")\n",
        "#     print(\"Loaded model!\")\n",
        "#     # print(\"Loading Text_Encoder...\")\n",
        "#     # clip = clip_loader.load_clip(\"t5xxl_fp8_e4m3fn_scaled.safetensors\", \"ltxv\", \"default\")[0]\n",
        "#     # print(\"Loaded Text_Encoder!\")\n",
        "\n",
        "\n",
        "def clear_memory():\n",
        "    \"\"\"Frees GPU (VRAM) and CPU RAM memory.\"\"\"\n",
        "    gc.collect()\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "        torch.cuda.ipc_collect()\n",
        "    for obj in list(globals().values()):\n",
        "        if torch.is_tensor(obj) or (hasattr(obj, \"data\") and torch.is_tensor(obj.data)):\n",
        "            del obj\n",
        "\n",
        "    gc.collect()\n",
        "\n",
        "def generate_video(\n",
        "    positive_prompt: str = \"A drone quickly rises through a bank of morning fog...\",\n",
        "    negative_prompt: str = \"low quality, worst quality...\",\n",
        "    width: int = 768,\n",
        "    height: int = 512,\n",
        "    seed: int = 0,\n",
        "    steps: int = 30,\n",
        "    cfg_scale: float = 2.05,\n",
        "    sampler_name: str = \"res_multistep\",\n",
        "    length: int = 49,\n",
        "    fps: int = 24\n",
        "):\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        print(\"Loading Text_Encoder...\")\n",
        "        clip = clip_loader.load_clip(\"t5xxl_fp8_e4m3fn_scaled.safetensors\", \"ltxv\", \"default\")[0]\n",
        "        print(\"Loaded Text_Encoder!\")\n",
        "\n",
        "    try:\n",
        "        assert width % 32 == 0, \"Width must be divisible by 32\"\n",
        "        assert height % 32 == 0, \"Height must be divisible by 32\"\n",
        "\n",
        "        positive = clip_encode_positive.encode(clip, positive_prompt)[0]\n",
        "        negative = clip_encode_negative.encode(clip, negative_prompt)[0]\n",
        "\n",
        "        del clip\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "        print(\"Text_Encoder removed from memory\")\n",
        "\n",
        "        empty_latent = empty_latent_video.generate(width, height, length)[0]\n",
        "\n",
        "        sigmas = scheduler.get_sigmas(steps, cfg_scale, 0.95, True, 0.1)[0]\n",
        "        selected_sampler = sampler_select.get_sampler(sampler_name)[0]\n",
        "        conditioned = conditioning.append(positive, negative, 25.0)\n",
        "\n",
        "        print(\"Loading model & VAE...\")\n",
        "        model, _, vae = checkpoint_loader.load_checkpoint(\"ltx-video-2b-v0.9.5.safetensors\")\n",
        "        print(\"Loaded model & VAE!\")\n",
        "\n",
        "        print(\"Generating video...\")\n",
        "        sampled = sampler.sample(\n",
        "            model=model,\n",
        "            add_noise=True,\n",
        "            noise_seed=seed if seed != 0 else random.randint(0, 2**32),\n",
        "            cfg=cfg_scale,\n",
        "            positive=conditioned[0],\n",
        "            negative=conditioned[1],\n",
        "            sampler=selected_sampler,\n",
        "            sigmas=sigmas,\n",
        "            latent_image=empty_latent\n",
        "        )[0]\n",
        "\n",
        "        del model\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "        print(\"Model removed from memory\")\n",
        "\n",
        "        with torch.no_grad():\n",
        "          try:\n",
        "              print(\"Decodimg Latents...\")\n",
        "              decoded = vae_decode.decode(vae, sampled)[0].detach()\n",
        "              print(\"Latents Decoded!\")\n",
        "              del vae\n",
        "              torch.cuda.empty_cache()\n",
        "              gc.collect()\n",
        "              print(\"VAE removed from memory\")\n",
        "\n",
        "              output_path = \"/content/output.mp4\"\n",
        "              with imageio.get_writer(output_path, fps=fps) as writer:\n",
        "                  for i, frame in enumerate(decoded):\n",
        "                      frame_np = (frame.cpu().numpy() * 255).astype(np.uint8)\n",
        "                      writer.append_data(frame_np)\n",
        "                      if i % 10 == 0:  # Periodic cleanup\n",
        "                          torch.cuda.empty_cache()\n",
        "\n",
        "              print(f\"Successfully processed {len(decoded)} frames\")\n",
        "\n",
        "\n",
        "          except Exception as e:\n",
        "              print(f\"Decoding error: {str(e)}\")\n",
        "              raise\n",
        "\n",
        "        print(\"Displaying Video...\")\n",
        "        display_video(output_path)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Video generation failed: {str(e)}\")\n",
        "        raise\n",
        "    finally:\n",
        "        clear_memory()\n",
        "\n",
        "def display_video(video_path):\n",
        "    from IPython.display import HTML\n",
        "    from base64 import b64encode\n",
        "\n",
        "    mp4 = open(video_path,'rb').read()\n",
        "    data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "\n",
        "    display(HTML(f\"\"\"\n",
        "    <video width=512 controls autoplay loop>\n",
        "        <source src=\"{data_url}\" type=\"video/mp4\">\n",
        "    </video>\n",
        "    \"\"\"))\n",
        "\n",
        "print(\"✅ Environment Setup Complete!\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "rrXFIT4fMfyJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32edfe3f-7fe8-4ed4-bc52-64d13bcf7a25"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch==2.6.0 in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision==0.21.0 in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.6.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.6.0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.6.0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.6.0)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.6.0)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.6.0)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch==2.6.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.6.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.6.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.6.0)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (1.13.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.21.0) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.21.0) (11.2.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.6.0) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m98.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "/content\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting av\n",
            "  Downloading av-15.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.6 kB)\n",
            "Downloading av-15.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (39.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.7/39.7 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: av\n",
            "Successfully installed av-15.0.0\n",
            "Cloning into 'ComfyUI'...\n",
            "remote: Enumerating objects: 19633, done.\u001b[K\n",
            "remote: Total 19633 (delta 0), reused 0 (delta 0), pack-reused 19633 (from 1)\u001b[K\n",
            "Receiving objects: 100% (19633/19633), 64.38 MiB | 19.41 MiB/s, done.\n",
            "Resolving deltas: 100% (13064/13064), done.\n",
            "/content/ComfyUI\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "The following additional packages will be installed:\n",
            "  libaria2-0 libc-ares2\n",
            "The following NEW packages will be installed:\n",
            "  aria2 libaria2-0 libc-ares2\n",
            "0 upgraded, 3 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 1,513 kB of archives.\n",
            "After this operation, 5,441 kB of additional disk space will be used.\n",
            "Selecting previously unselected package libc-ares2:amd64.\n",
            "(Reading database ... 126281 files and directories currently installed.)\n",
            "Preparing to unpack .../libc-ares2_1.18.1-1ubuntu0.22.04.3_amd64.deb ...\n",
            "Unpacking libc-ares2:amd64 (1.18.1-1ubuntu0.22.04.3) ...\n",
            "Selecting previously unselected package libaria2-0:amd64.\n",
            "Preparing to unpack .../libaria2-0_1.36.0-1_amd64.deb ...\n",
            "Unpacking libaria2-0:amd64 (1.36.0-1) ...\n",
            "Selecting previously unselected package aria2.\n",
            "Preparing to unpack .../aria2_1.36.0-1_amd64.deb ...\n",
            "Unpacking aria2 (1.36.0-1) ...\n",
            "Setting up libc-ares2:amd64 (1.18.1-1ubuntu0.22.04.3) ...\n",
            "Setting up libaria2-0:amd64 (1.36.0-1) ...\n",
            "Setting up aria2 (1.36.0-1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "\u001b[0m\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "e62459|\u001b[1;32mOK\u001b[0m  |   196MiB/s|/content/ComfyUI/models/checkpoints/ltx-video-2b-v0.9.5.safetensors\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\u001b[0m\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "f35dfb|\u001b[1;32mOK\u001b[0m  |   130MiB/s|/content/ComfyUI/models/text_encoders/t5xxl_fp8_e4m3fn_scaled.safetensors\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "✅ Environment Setup Complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Prepare Environment and Install Server Libraries\n",
        "!pip install torch==2.6.0 torchvision==0.21.0\n",
        "# %cd /content # Comentamos esto si queremos que el server corra en la raíz\n",
        "Always_Load_Models_for_Inference = False\n",
        "Use_t5xxl_fp16 = False\n",
        "    # Install dependencies for video generation\n",
        "!pip install -q torchsde einops diffusers accelerate xformers==0.0.29.post2\n",
        "!pip install av\n",
        "!git clone https://github.com/Isi-dev/ComfyUI /content/ComfyUI # Clonar ComfyUI en una ubicación conocida\n",
        "    # %cd /content/ComfyUI # Comentamos esto para mantener la raíz como directorio de trabajo del server\n",
        "!apt -y install -qq aria2 ffmpeg\n",
        "\n",
        "    # Download required models\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Isi99999/LTX-Video/resolve/main/ltx-video-2b-v0.9.5.safetensors -d /content/ComfyUI/models/checkpoints -o ltx-video-2b-v0.9.5.safetensors\n",
        "if Use_t5xxl_fp16:\n",
        "        !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Isi99999/LTX-Video/resolve/main/t5xxl_fp16.safetensors -d /content/ComfyUI/models/text_encoders -o t5xxl_fp16.safetensors\n",
        "else:\n",
        "        !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Isi99999/LTX-Video/resolve/main/t5xxl_fp8_e4m3fn_scaled.safetensors -d /content/ComfyUI/models/text_encoders -o t5xxl_fp8_e4m3fn_scaled.safetensors\n",
        "\n",
        "    # --- Install Server Libraries ---\n",
        "!pip install fastapi uvicorn pyngrok google-cloud-storage\n",
        "\n",
        "    # Initial setup for video generation code\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import gc\n",
        "import sys\n",
        "import random\n",
        "import os\n",
        "import imageio\n",
        "    # from google.colab import files # No necesario en el servidor\n",
        "    # from IPython.display import display, HTML # No necesario en el servidor\n",
        "\n",
        "    # Add ComfyUI directory to sys.path\n",
        "sys.path.insert(0, '/content/ComfyUI')\n",
        "\n",
        "from comfy import model_management\n",
        "\n",
        "from nodes import (\n",
        "        CheckpointLoaderSimple,\n",
        "        CLIPLoader,\n",
        "        CLIPTextEncode,\n",
        "        VAEDecode\n",
        "    )\n",
        "\n",
        "from comfy_extras.nodes_custom_sampler import (\n",
        "        KSamplerSelect,\n",
        "        SamplerCustom\n",
        "    )\n",
        "\n",
        "from comfy_extras.nodes_lt import (\n",
        "        LTXVConditioning,\n",
        "        LTXVScheduler,\n",
        "        EmptyLTXVLatentVideo\n",
        "    )\n",
        "\n",
        "    # Initialize nodes\n",
        "checkpoint_loader = CheckpointLoaderSimple()\n",
        "clip_loader = CLIPLoader()\n",
        "clip_encode_positive = CLIPTextEncode()\n",
        "clip_encode_negative = CLIPTextEncode()\n",
        "scheduler = LTXVScheduler()\n",
        "sampler_select = KSamplerSelect()\n",
        "conditioning = LTXVConditioning()\n",
        "empty_latent_video = EmptyLTXVLatentVideo()\n",
        "sampler = SamplerCustom()\n",
        "vae_decode = VAEDecode()\n",
        "\n",
        "    # --- Google Cloud Storage Upload Function ---\n",
        "from google.cloud import storage\n",
        "\n",
        "def upload_video_to_gcs(source_file_name, destination_blob_name, bucket_name):\n",
        "        \"\"\"Sube un archivo a un bucket de Cloud Storage.\"\"\"\n",
        "        # Colab generalmente usa las credenciales de usuario, que deberían tener acceso a GCS si el usuario lo tiene.\n",
        "        # Si esto falla, puede que necesites autenticarte explícitamente usando una cuenta de servicio.\n",
        "        storage_client = storage.Client()\n",
        "        bucket = storage_client.bucket(bucket_name)\n",
        "        blob = bucket.blob(destination_blob_name)\n",
        "\n",
        "        blob.upload_from_filename(source_file_name)\n",
        "\n",
        "        print(f\"Archivo {source_file_name} subido a {destination_blob_name} en el bucket {bucket_name}.\")\n",
        "        return f\"gs://{bucket_name}/{destination_blob_name}\" # Retornar la ruta GS\n",
        "\n",
        "    # --- Modified Video Generation Function to Save to GCS ---\n",
        "def generate_video(\n",
        "        positive_prompt: str,\n",
        "        negative_prompt: str,\n",
        "        width: int,\n",
        "        height: int,\n",
        "        seed: int,\n",
        "        steps: int,\n",
        "        cfg_scale: float,\n",
        "        sampler_name: str,\n",
        "        length: int,\n",
        "        fps: int,\n",
        "        output_bucket_name: str, # Parameter for the output GCS bucket name\n",
        "        output_blob_prefix: str # Parameter for the prefix of the output file name in GCS\n",
        "    ):\n",
        "\n",
        "        with torch.inference_mode():\n",
        "            print(\"Loading Text_Encoder...\")\n",
        "            # Assuming models are downloaded to /content/ComfyUI/models\n",
        "            clip = clip_loader.load_clip(\"/content/ComfyUI/models/text_encoders/t5xxl_fp8_e4m3fn_scaled.safetensors\", \"ltxv\", \"default\")[0]\n",
        "            print(\"Loaded Text_Encoder!\")\n",
        "\n",
        "        try:\n",
        "            assert width % 32 == 0, \"Width must be divisible by 32\"\n",
        "            assert height % 32 == 0, \"Height must be divisible by 32\"\n",
        "\n",
        "            positive = clip_encode_positive.encode(clip, positive_prompt)[0]\n",
        "            negative = clip_encode_negative.encode(clip, negative_prompt)[0]\n",
        "\n",
        "            del clip\n",
        "            torch.cuda.empty_cache()\n",
        "            gc.collect()\n",
        "            print(\"Text_Encoder removed from memory\")\n",
        "\n",
        "            empty_latent = empty_latent_video.generate(width, height, length)[0]\n",
        "\n",
        "            sigmas = scheduler.get_sigmas(steps, cfg_scale, 0.95, True, 0.1)[0]\n",
        "            selected_sampler = sampler_select.get_sampler(sampler_name)[0]\n",
        "            conditioned = conditioning.append(positive, negative, 25.0)\n",
        "\n",
        "            print(\"Loading model & VAE...\")\n",
        "            # Assuming models are downloaded to /content/ComfyUI/models\n",
        "            model, _, vae = checkpoint_loader.load_checkpoint(\"/content/ComfyUI/models/checkpoints/ltx-video-2b-v0.9.5.safetensors\")\n",
        "            print(\"Loaded model & VAE!\")\n",
        "\n",
        "            print(\"Generando video...\")\n",
        "            sampled = sampler.sample(\n",
        "                model=model,\n",
        "                add_noise=True,\n",
        "                noise_seed=seed if seed != 0 else random.randint(0, 2**32),\n",
        "                cfg=cfg_scale,\n",
        "                positive=conditioned[0],\n",
        "                negative=conditioned[1],\n",
        "                sampler=selected_sampler,\n",
        "                sigmas=sigmas,\n",
        "                latent_image=empty_latent\n",
        "            )[0]\n",
        "\n",
        "            del model\n",
        "            torch.cuda.empty_cache()\n",
        "            gc.collect()\n",
        "            print(\"Model removed from memory\")\n",
        "\n",
        "            with torch.no_grad():\n",
        "              try:\n",
        "                  print(\"Decodificando Latents...\")\n",
        "                  decoded = vae_decode.decode(vae, sampled)[0].detach()\n",
        "                  print(\"Latents Decoded!\")\n",
        "                  del vae\n",
        "                  torch.cuda.empty_cache()\n",
        "                  gc.collect()\n",
        "                  print(\"VAE removed from memory\")\n",
        "\n",
        "                  # --- Save video to temporary file and upload to GCS ---\n",
        "                  temp_output_path = \"/tmp/output.mp4\" # Save temporarily\n",
        "                  with imageio.get_writer(temp_output_path, fps=fps) as writer:\n",
        "                      for i, frame in enumerate(decoded):\n",
        "                          frame_np = (frame.cpu().numpy() * 255).astype(np.uint8)\n",
        "                          writer.append_data(frame_np)\n",
        "                          if i % 10 == 0:  # Periodic cleanup\n",
        "                              torch.cuda.empty_cache()\n",
        "\n",
        "                  print(f\"Successfully processed {len(decoded)} frames\")\n",
        "\n",
        "                  # Generate a unique name for the file in GCS\n",
        "                  import uuid\n",
        "                  gcs_blob_name = f\"{output_blob_prefix}/{uuid.uuid4().hex}.mp4\"\n",
        "\n",
        "                  # Upload the video to Cloud Storage\n",
        "                  video_gcs_path = upload_video_to_gcs(temp_output_path, gcs_blob_name, output_bucket_name)\n",
        "\n",
        "                  print(f\"Video generated and uploaded to Cloud Storage: {video_gcs_path}\")\n",
        "\n",
        "                  # Clean up the temporary local file\n",
        "                  os.remove(temp_output_path)\n",
        "                  print(f\"Removed temporary file: {temp_output_path}\")\n",
        "\n",
        "                  return video_gcs_path # Return the GCS path\n",
        "\n",
        "              except Exception as e:\n",
        "                  print(f\"Decoding error: {str(e)}\")\n",
        "                  raise\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Video generation failed: {str(e)}\")\n",
        "            raise\n",
        "        finally:\n",
        "            clear_memory() # Final memory cleanup\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82l34eUHIIVH",
        "outputId": "12501f44-7b69-4c73-dd7e-5288d14fefd1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch==2.6.0 in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision==0.21.0 in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (1.13.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.21.0) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.21.0) (11.2.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.6.0) (3.0.2)\n",
            "Requirement already satisfied: av in /usr/local/lib/python3.11/dist-packages (15.0.0)\n",
            "fatal: destination path '/content/ComfyUI' already exists and is not an empty directory.\n",
            "aria2 is already the newest version (1.36.0-1).\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n",
            "\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "b52173|\u001b[1;32mOK\u001b[0m  |       0B/s|/content/ComfyUI/models/checkpoints/ltx-video-2b-v0.9.5.safetensors\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "35b864|\u001b[1;32mOK\u001b[0m  |       0B/s|/content/ComfyUI/models/text_encoders/t5xxl_fp8_e4m3fn_scaled.safetensors\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.11/dist-packages (0.116.0)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.11/dist-packages (0.35.0)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.12-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.11/dist-packages (2.19.0)\n",
            "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (0.46.2)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from fastapi) (2.11.7)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (4.14.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (8.2.1)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (0.16.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: google-auth<3.0dev,>=2.26.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage) (2.38.0)\n",
            "Requirement already satisfied: google-api-core<3.0.0dev,>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage) (2.25.1)\n",
            "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage) (2.4.3)\n",
            "Requirement already satisfied: google-resumable-media>=2.7.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage) (2.7.2)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage) (2.32.3)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage) (1.7.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage) (1.70.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage) (5.29.5)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage) (1.26.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage) (4.9.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2025.7.9)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.47.0,>=0.40.0->fastapi) (4.9.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=2.26.1->google-cloud-storage) (0.6.1)\n",
            "Downloading pyngrok-7.2.12-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.2.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- FastAPI Server Setup ---\n",
        "from fastapi import FastAPI, HTTPException\n",
        "from pydantic import BaseModel\n",
        "import nest_asyncio\n",
        "import uvicorn\n",
        "from pyngrok import ngrok\n",
        "import os\n",
        "\n",
        "    # Pydantic model for request body validation\n",
        "class VideoRequest(BaseModel):\n",
        "        positive_prompt: str\n",
        "        negative_prompt: str\n",
        "        width: int\n",
        "        height: int\n",
        "        seed: int = 0\n",
        "        steps: int = 25\n",
        "        cfg_scale: float = 2.05\n",
        "        sampler_name: str = \"res_multistep\"\n",
        "        length: int = 73\n",
        "        fps: int = 24\n",
        "        output_bucket_name: str # Name of the GCS bucket\n",
        "        output_blob_prefix: str = \"generated_videos\" # Prefix for the file name in GCS\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "@app.post(\"/generate-video\")\n",
        "async def generate_video_endpoint(request: VideoRequest):\n",
        "        \"\"\"Receives video generation parameters and returns the GCS path of the generated video.\"\"\"\n",
        "        try:\n",
        "            print(\"Received video generation request:\", request)\n",
        "\n",
        "            video_gcs_path = generate_video(\n",
        "                positive_prompt=request.positive_prompt,\n",
        "                negative_prompt=request.negative_prompt,\n",
        "                width=request.width,\n",
        "                height=request.height,\n",
        "                seed=request.seed,\n",
        "                steps=request.steps,\n",
        "                cfg_scale=request.cfg_scale,\n",
        "                sampler_name=request.sampler_name,\n",
        "                length=request.length,\n",
        "                fps=request.fps,\n",
        "                output_bucket_name=request.output_bucket_name,\n",
        "                output_blob_prefix=request.output_blob_prefix\n",
        "            )\n",
        "\n",
        "            return {\"video_gcs_path\": video_gcs_path}\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in generate_video_endpoint: {str(e)}\")\n",
        "            raise HTTPException(status_code=500, detail=f\"Video generation failed: {str(e)}\")\n"
      ],
      "metadata": {
        "id": "3yqzOgKMIUaO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Pyngrok and Uvicorn Setup to run the FastAPI app ---\\\n",
        "    # Make Colab compatible with asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "    # Configure ngrok auth token (Replace with your actual ngrok token or read from a secret)\n",
        "    # You can get an ngrok token from your ngrok dashboard after signing up.\n",
        "    # conf.get_default().auth_token =  \"YOUR_NGROK_AUTH_TOKEN\"\\\n",
        "    # WARNING: Storing tokens directly in the notebook is NOT secure. Use Colab Secrets if possible.\n",
        "try:\n",
        "        from google.colab import userdata\n",
        "        NGROK_AUTH_TOKEN = userdata.get('NGROK_AUTH_TOKEN') # Assuming you saved your ngrok token as 'NGROK_AUTH_TOKEN' in Colab Secrets\n",
        "        ngrok.set_auth_token(NGROK_AUTH_TOKEN) # Use set_auth_token instead of conf\n",
        "\n",
        "except:\n",
        "        print(\"Colab Secrets not available or NGROK_AUTH_TOKEN not found. Pyngrok might not work without auth token.\")\n",
        "        print(\"Please add your ngrok auth token as a Colab Secret named 'NGROK_AUTH_TOKEN'.\")\n",
        "\n",
        "    # Define the port for the FastAPI app\n",
        "COLAB_PORT = 8000 # Or any other available port\n",
        "\n",
        "    # Start ngrok tunnel\n",
        "print(f\"Starting ngrok tunnel for port {COLAB_PORT}...\")\n",
        "    # Disconnect existing tunnels to avoid conflicts\n",
        "ngrok.kill()\n",
        "public_url = ngrok.connect(COLAB_PORT).public_url\n",
        "print(f\"🔥 Public ngrok URL: {public_url}\")\n",
        "\n",
        "    # --- IMPORTANT --- #\n",
        "    # You need to send this public_url to your backend (e.g., Firebase Realtime Database or Firestore)\\\n",
        "    # so your Cloud Function knows where to send requests.\\\n",
        "    # Example (requires Firebase Admin SDK setup in Colab, which adds complexity):\\\n",
        "    # from firebase_admin import db # Example for Realtime Database\\\n",
        "    # db.reference('/colab_server_url').set(public_url)\\\n",
        "    # For simplicity now, you'll manually copy this URL to your backend config.\\\n",
        "    # ----------------- #\n",
        "\n",
        "    # Run the FastAPI app using uvicorn\n",
        "print(f\"Running FastAPI app on port {COLAB_PORT}...\")\n",
        "uvicorn.run(app, host=\"0.0.0.0\", port=COLAB_PORT)\n",
        "\n",
        "    # This cell will block execution as it runs the server. You'll need to stop it manually if running interactively.\n",
        "    # For automation, you might need to adjust how uvicorn is run or explore other ways to keep the Colab session alive and the server running.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oreyqhiOIbGm",
        "outputId": "6acbc792-6661-44ca-b646-a7ce7b0f0414"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting ngrok tunnel for port 8000...\n",
            "🔥 Public ngrok URL: https://089a4f5c510f.ngrok-free.app\n",
            "Running FastAPI app on port 8000...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Started server process [622]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n",
            "INFO:     Shutting down\n",
            "INFO:     Waiting for application shutdown.\n",
            "INFO:     Application shutdown complete.\n",
            "INFO:     Finished server process [622]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "#  PASO 1: Instalar todas las librerías necesarias\n",
        "# ==============================================================================\n",
        "!pip install fastapi \"uvicorn[standard]\" pyngrok nest_asyncio cloudinary -q\n",
        "\n",
        "# ==============================================================================\n",
        "#  PASO 2: Importar librerías y configurar el servidor\n",
        "# ==============================================================================\n",
        "import os\n",
        "import asyncio\n",
        "from fastapi import FastAPI, HTTPException\n",
        "from pyngrok import ngrok\n",
        "import nest_asyncio\n",
        "import uvicorn\n",
        "\n",
        "# Importaciones de Cloudinary y para leer los Secrets de Colab\n",
        "import cloudinary\n",
        "import cloudinary.uploader\n",
        "from google.colab import userdata\n",
        "\n",
        "# --- Configuración de Cloudinary ---\n",
        "# El código lee las claves de forma segura desde los \"Secrets\" de Colab\n",
        "try:\n",
        "    cloudinary.config(\n",
        "      cloud_name = userdata.get('CLOUDINARY_CLOUD_NAME'),\n",
        "      api_key = userdata.get('CLOUDINARY_API_KEY'),\n",
        "      api_secret = userdata.get('CLOUDINARY_API_SECRET'),\n",
        "      secure = True\n",
        "    )\n",
        "    print(\"✅ Configuración de Cloudinary exitosa.\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Error al configurar Cloudinary. Asegúrate de que los secrets (CLOUDINARY_CLOUD_NAME, CLOUDINARY_API_KEY, CLOUDINARY_API_SECRET) están bien guardados. Error: {e}\")\n",
        "\n",
        "# --- Definición de la aplicación FastAPI ---\n",
        "app = FastAPI()\n",
        "\n",
        "@app.post(\"/generate-video/\")\n",
        "async def generate_video_endpoint(prompt: str):\n",
        "    \"\"\"\n",
        "    Endpoint que simula la creación de un video, lo sube a Cloudinary\n",
        "    y devuelve la URL pública segura.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        print(f\"▶️ Solicitud recibida. Generando video para: '{prompt}'\")\n",
        "\n",
        "        # Simulación de la generación del video\n",
        "        video_filename = \"video_generado.mp4\"\n",
        "        video_path = f\"/content/{video_filename}\"\n",
        "        with open(video_path, \"w\") as f:\n",
        "            f.write(f\"Este es un video de prueba para el prompt: {prompt}\")\n",
        "        print(f\"✔️ Video simulado creado en: {video_path}\")\n",
        "\n",
        "        # Subir el video a Cloudinary\n",
        "        print(\"☁️ Subiendo video a Cloudinary...\")\n",
        "        upload_result = cloudinary.uploader.upload_video(video_path, resource_type=\"video\")\n",
        "        public_url = upload_result['secure_url']\n",
        "        print(f\"✔️ Subida completada. URL: {public_url}\")\n",
        "\n",
        "        os.remove(video_path) # Limpiar el archivo local\n",
        "\n",
        "        return {\"status\": \"éxito\", \"video_url\": public_url}\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Ocurrió un error grave en el endpoint: {e}\")\n",
        "        raise HTTPException(status_code=500, detail=str(e))\n",
        "\n",
        "# ==============================================================================\n",
        "#  PASO 3: Iniciar el túnel ngrok y arrancar el servidor\n",
        "# ==============================================================================\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Configurar el token de autenticación de ngrok desde los Secrets\n",
        "try:\n",
        "    NGROK_AUTH_TOKEN = userdata.get('NGROK_AUTH_TOKEN')\n",
        "    ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "    print(\"✅ Token de autenticación de ngrok configurado.\")\n",
        "except Exception as e:\n",
        "    print(\"❌ No se pudo encontrar el NGROK_AUTH_TOKEN en los Secrets de Colab.\")\n",
        "\n",
        "# Iniciar el túnel\n",
        "COLAB_PORT = 8000\n",
        "ngrok.kill() # Cierra túneles anteriores\n",
        "public_url = ngrok.connect(COLAB_PORT).public_url\n",
        "print(\"======================================================================\")\n",
        "print(f\"🔥 TU SERVIDOR ESTÁ LISTO Y EN LÍNEA EN ESTA URL PÚBLICA:\")\n",
        "print(f\"   {public_url}\")\n",
        "print(\"======================================================================\")\n",
        "\n",
        "# Arrancar el servidor FastAPI\n",
        "uvicorn.run(app, host=\"0.0.0.0\", port=COLAB_PORT)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qc294KyvmAwO",
        "outputId": "19eba6c3-e2de-46ed-b452-fd60b9f42ecd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:asyncio:Task exception was never retrieved\n",
            "future: <Task finished name='Task-7' coro=<Server.serve() done, defined at /usr/local/lib/python3.11/dist-packages/uvicorn/server.py:69> exception=KeyboardInterrupt()>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/main.py\", line 580, in run\n",
            "    server.run()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/server.py\", line 67, in run\n",
            "    return asyncio.run(self.serve(sockets=sockets))\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/nest_asyncio.py\", line 30, in run\n",
            "    return loop.run_until_complete(task)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/nest_asyncio.py\", line 92, in run_until_complete\n",
            "    self._run_once()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/nest_asyncio.py\", line 133, in _run_once\n",
            "    handle._run()\n",
            "  File \"/usr/lib/python3.11/asyncio/events.py\", line 84, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/usr/lib/python3.11/asyncio/tasks.py\", line 360, in __wakeup\n",
            "    self.__step()\n",
            "  File \"/usr/lib/python3.11/asyncio/tasks.py\", line 277, in __step\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/server.py\", line 70, in serve\n",
            "    with self.capture_signals():\n",
            "  File \"/usr/lib/python3.11/contextlib.py\", line 144, in __exit__\n",
            "    next(self.gen)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/server.py\", line 331, in capture_signals\n",
            "    signal.raise_signal(captured_signal)\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/147.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/459.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/4.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m183.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m92.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/453.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m453.1/453.1 kB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:asyncio:Task exception was never retrieved\n",
            "future: <Task finished name='Task-1' coro=<Server.serve() done, defined at /usr/local/lib/python3.11/dist-packages/uvicorn/server.py:69> exception=KeyboardInterrupt()>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/main.py\", line 580, in run\n",
            "    server.run()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/server.py\", line 67, in run\n",
            "    return asyncio.run(self.serve(sockets=sockets))\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/nest_asyncio.py\", line 30, in run\n",
            "    return loop.run_until_complete(task)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/nest_asyncio.py\", line 92, in run_until_complete\n",
            "    self._run_once()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/nest_asyncio.py\", line 133, in _run_once\n",
            "    handle._run()\n",
            "  File \"/usr/lib/python3.11/asyncio/events.py\", line 84, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/usr/lib/python3.11/asyncio/tasks.py\", line 360, in __wakeup\n",
            "    self.__step()\n",
            "  File \"/usr/lib/python3.11/asyncio/tasks.py\", line 277, in __step\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/server.py\", line 70, in serve\n",
            "    with self.capture_signals():\n",
            "  File \"/usr/lib/python3.11/contextlib.py\", line 144, in __exit__\n",
            "    next(self.gen)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/server.py\", line 331, in capture_signals\n",
            "    signal.raise_signal(captured_signal)\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Configuración de Cloudinary exitosa.\n",
            "✅ Token de autenticación de ngrok configurado.\n",
            "======================================================================\n",
            "🔥 TU SERVIDOR ESTÁ LISTO Y EN LÍNEA EN ESTA URL PÚBLICA:\n",
            "   https://4cdb2a237b32.ngrok-free.app\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Started server process [622]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"
          ]
        }
      ]
    }
  ]
}